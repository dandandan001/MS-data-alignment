{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: deisotope\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from ms_deisotope import deconvolute_peaks, Averagine, MSDeconVFitter\n",
    "import os\n",
    "\n",
    "\n",
    "# Specify the directory containing your CSV or xlsx files\n",
    "input_directory = \"Input_files_folder\"\n",
    "# Specify the directory to save the results\n",
    "output_directory = \"Output_files_folder\"\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "from ms_deisotope import Averagine\n",
    "\n",
    "for file_path in glob.glob(input_directory+ '/*.csv'):\n",
    "    df = pd.read_csv(file_path, header=[1])\n",
    "    peaks = list(zip(df['mass'], df['abund']))\n",
    "    # Define your custom averagine model\n",
    "    custom_averagine = Averagine({\"C\": 4.9384, \"H\": 7.7583, \"N\": 1.3577, \"O\": 1.4773, \"S\": 0.0417})\n",
    "    scorer = MSDeconVFitter(1.5) # change the value based on your data\n",
    "    deconvoluted_peaks, _ = deconvolute_peaks(peaks, averagine=custom_averagine, scorer=scorer)\n",
    "\n",
    "    # Create a DataFrame from the deconvoluted peaks\n",
    "    # Assuming each peak in deconvoluted_peaks has 'mz' and 'abund' attributes\n",
    "    mz_values = [peak.mz for peak in deconvoluted_peaks]\n",
    "    abund_values = [peak.intensity for peak in deconvoluted_peaks]\n",
    "\n",
    "    # Create a DataFrame using a dictionary to map column names to data lists\n",
    "    deisotoped_df = pd.DataFrame({'mass': mz_values, 'abund': abund_values})\n",
    "\n",
    "    # Define the output file path\n",
    "    base_name = os.path.basename(file_path)\n",
    "    output_file_path = os.path.join(output_directory, 'deisotoped_' + base_name)\n",
    "\n",
    "    # Save the deisotoped data to the new folder\n",
    "    deisotoped_df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bee2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: average all the m/z values within 0.01 m/z range, to generate a list of m/z for alignment\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the directory containing your CSV files\n",
    "input_directory = \"Input_files_folder\"\n",
    "output_directory = \"Output_files_folder\"\n",
    "\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "    \n",
    "# Initialize an empty DataFrame to store all data\n",
    "all_data = pd.DataFrame(columns=['mass', 'abund'])\n",
    "\n",
    "# Loop over all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    # Check if the file is a CSV file\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        filepath = os.path.join(input_directory, filename)\n",
    "\n",
    "        # Load the data from the CSV file\n",
    "        data = pd.read_csv(filepath)\n",
    "\n",
    "        # Append the data to the all_data DataFrame\n",
    "        all_data = all_data.append(data)\n",
    "\n",
    "# Sort the DataFrame by 'mass'\n",
    "all_data = all_data.sort_values('mass')\n",
    "\n",
    "# Initialize an empty DataFrame to store the averaged data\n",
    "averaged_data = pd.DataFrame(columns=['mass', 'abund'])\n",
    "\n",
    "# Initialize the first row\n",
    "current_row = all_data.iloc[0]\n",
    "current_row_values = [current_row]\n",
    "\n",
    "# Loop over the rest of the rows\n",
    "for i in range(1, len(all_data)):\n",
    "    # If the 'mass' value of the next row is close to the current one\n",
    "    if np.abs(all_data.iloc[i]['mass'] - current_row['mass']) <= 0.01:\n",
    "        # Add the current row to the list of similar rows\n",
    "        current_row_values.append(all_data.iloc[i])\n",
    "    else:\n",
    "        # Calculate the average of the 'mass' and 'intensity' values of the similar rows\n",
    "        averaged_row = pd.DataFrame([{\n",
    "            'mass': np.mean([row['mass'] for row in current_row_values]),\n",
    "            'abund': np.mean([row['abund'] for row in current_row_values])\n",
    "        }])\n",
    "        # Append the averaged row to the averaged_data DataFrame\n",
    "        averaged_data = averaged_data.append(averaged_row, ignore_index=True)\n",
    "\n",
    "        # Move on to the next row\n",
    "        current_row = all_data.iloc[i]\n",
    "        current_row_values = [current_row]\n",
    "\n",
    "# Calculate the average of the 'mass' and 'intensity' values of the last group of similar rows\n",
    "averaged_row = pd.DataFrame([{\n",
    "    'mass': np.mean([row['mass'] for row in current_row_values]),\n",
    "    'abund': np.mean([row['abund'] for row in current_row_values])\n",
    "}])\n",
    "# Append the averaged row to the averaged_data DataFrame\n",
    "averaged_data = averaged_data.append(averaged_row, ignore_index=True)\n",
    "\n",
    "averaged_data.to_csv(os.path.join(output_directory, \"average_all_mz_from_deisotoped.csv\"), index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f02cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: align all deisotoped csv files/peaks\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# specify the directory you want to use\n",
    "input_dir = \"Input_files_folder\"\n",
    "output_dir = \"Output_files_folder\"\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# read all csv files and store them in a dictionary\n",
    "dataframes = {}\n",
    "all_mz_values = []\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(input_dir, filename))\n",
    "        dataframes[filename] = df\n",
    "        all_mz_values.extend(df.iloc[:, 0].values)\n",
    "\n",
    "# define the m/z difference tolerance\n",
    "mz_tolerance = 0.01\n",
    "\n",
    "# define the ppm difference tolerance\n",
    "ppm_tolerance = 5\n",
    "\n",
    "# get a unique m/z value list\n",
    "unique_mz = pd.read_csv(\"average_all_mz_from_deisotoped.csv\") # this is the m/z list csv file generated from average\n",
    "unique_mz_values = unique_mz.mass.to_list()\n",
    "\n",
    "# iterate over all dataframes\n",
    "for filename, df in dataframes.items():\n",
    "    # iterate over all 'm/z' values in df\n",
    "    for i in range(len(df)):\n",
    "        # find the 'm/z' values in the unique list that are within the tolerance\n",
    "        indices = np.where((np.abs(np.array(unique_mz_values) - df.iloc[i, 0]) <= mz_tolerance) | (np.abs((np.array(unique_mz_values) - df.iloc[i, 0]) / df.iloc[i, 0] * 1e6) <= ppm_tolerance))[0]\n",
    "        \n",
    "        # if the 'm/z' value exists in the unique list, replace it with the 'm/z' value in the unique list\n",
    "        if indices.size > 0:\n",
    "            df.iloc[i, 0] = unique_mz_values[indices[0]]\n",
    "    \n",
    "    # save the result as a new csv file\n",
    "    df.to_csv(os.path.join(output_dir, 'aligned_' + filename), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
